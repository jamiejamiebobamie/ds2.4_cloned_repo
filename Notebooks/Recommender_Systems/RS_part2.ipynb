{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems (RS):\n",
    "\n",
    "- We can use deep learning to predict rating for users based on the items\n",
    "\n",
    "- We use the Movielens-100k dataset for illustration. There are 943 users and 1682 movies. In total there are a 100k ratings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "u_cols = ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./Movie_Lens/users.dat', sep='::', names=u_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id sex  age  occupation zip_code\n",
      "0        1   F    1          10    48067\n",
      "1        2   M   56          16    70072\n",
      "2        3   M   25          15    55117\n",
      "3        4   M   45           7    02460\n",
      "4        5   M   25          20    55455\n"
     ]
    }
   ],
   "source": [
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./Movie_Lens/ratings.dat', sep='::', names=r_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  unix_timestamp\n",
      "0        1      1193       5       978300760\n",
      "1        1       661       3       978302109\n",
      "2        1       914       3       978301968\n",
      "3        1      3408       4       978300275\n",
      "4        1      2355       5       978824291\n"
     ]
    }
   ],
   "source": [
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "m_cols = ['movie_id', 'title', 'Genre']\n",
    "movies = pd.read_csv('./Movie_Lens/movies.dat', sep='::', names=m_cols, usecols=range(5), encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id                               title                         Genre\n",
      "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4         5  Father of the Bride Part II (1995)                        Comedy\n"
     ]
    }
   ],
   "source": [
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating\n",
      "0        1         1       5\n",
      "1        1        48       5\n",
      "2        1       150       5\n",
      "3        1       260       4\n",
      "4        1       527       5\n"
     ]
    }
   ],
   "source": [
    "movie_ratings = pd.merge(movies, ratings)\n",
    "lens = pd.merge(movie_ratings, users)\n",
    "\n",
    "dataset = lens[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n"
     ]
    }
   ],
   "source": [
    "print(dataset['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706\n"
     ]
    }
   ],
   "source": [
    "print(dataset['movie_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./ml-100k/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n"
     ]
    }
   ],
   "source": [
    "print(dataset['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "print(dataset['item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 12.1125 - acc: 0.0073\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 1s 19us/step - loss: 4.5957 - acc: 0.1435\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 1s 19us/step - loss: 1.9397 - acc: 0.2968\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 1s 19us/step - loss: 1.3165 - acc: 0.3580\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 1.0851 - acc: 0.3897\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.9851 - acc: 0.4043\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.9375 - acc: 0.4104\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.9117 - acc: 0.4145\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8975 - acc: 0.4157\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8878 - acc: 0.4166\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8818 - acc: 0.4180\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8768 - acc: 0.4186\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8733 - acc: 0.4180\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8705 - acc: 0.4190\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8680 - acc: 0.4183\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.8670 - acc: 0.4195\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.8648 - acc: 0.4203\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8631 - acc: 0.4198\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8615 - acc: 0.4195\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8601 - acc: 0.4205\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.8581 - acc: 0.4200\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8567 - acc: 0.4217\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8548 - acc: 0.4221\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8525 - acc: 0.4224\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8499 - acc: 0.4234\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8470 - acc: 0.4242\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8440 - acc: 0.4241\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8404 - acc: 0.4246\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8359 - acc: 0.4264\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8313 - acc: 0.4271\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8267 - acc: 0.4288\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8214 - acc: 0.4311\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8164 - acc: 0.4319\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8113 - acc: 0.4338\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8063 - acc: 0.4357\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.8014 - acc: 0.4363\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7971 - acc: 0.4362\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7925 - acc: 0.4397\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7885 - acc: 0.4415\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7853 - acc: 0.4421\n",
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7814 - acc: 0.4418\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7786 - acc: 0.4437\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7754 - acc: 0.4441\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 1s 19us/step - loss: 0.7724 - acc: 0.4461\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 1s 19us/step - loss: 0.7697 - acc: 0.4465\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7673 - acc: 0.4470\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7647 - acc: 0.4493\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7622 - acc: 0.4496\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7601 - acc: 0.4498\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7584 - acc: 0.4513\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7559 - acc: 0.4525\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7541 - acc: 0.4530\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7522 - acc: 0.4532\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 1s 18us/step - loss: 0.7506 - acc: 0.4546\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 2s 19us/step - loss: 0.7492 - acc: 0.4550\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7478 - acc: 0.4551\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7464 - acc: 0.4560\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7448 - acc: 0.4553\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7435 - acc: 0.4573\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.7423 - acc: 0.4568\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.7412 - acc: 0.4583\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.7401 - acc: 0.4588\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7391 - acc: 0.4586\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7379 - acc: 0.4579\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7367 - acc: 0.4590\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7362 - acc: 0.4598\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7350 - acc: 0.4590\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 2s 25us/step - loss: 0.7342 - acc: 0.4590\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7333 - acc: 0.4598\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7327 - acc: 0.4614\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7316 - acc: 0.4604\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 2s 24us/step - loss: 0.7308 - acc: 0.4614\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 2s 25us/step - loss: 0.7301 - acc: 0.4610\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7296 - acc: 0.4623\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7288 - acc: 0.4621\n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7284 - acc: 0.4612\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7272 - acc: 0.4627\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.7270 - acc: 0.4624\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7262 - acc: 0.4617\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 2s 23us/step - loss: 0.7255 - acc: 0.4615\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 2s 22us/step - loss: 0.7252 - acc: 0.4629\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7247 - acc: 0.4624\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7239 - acc: 0.4634\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7235 - acc: 0.4640\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7229 - acc: 0.4633\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7223 - acc: 0.4633\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7219 - acc: 0.4636\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7215 - acc: 0.4626\n",
      "Epoch 89/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7208 - acc: 0.4639\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7209 - acc: 0.4637\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 2s 21us/step - loss: 0.7200 - acc: 0.4643\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7197 - acc: 0.4633\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7195 - acc: 0.4650\n",
      "Epoch 94/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7191 - acc: 0.4635\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7184 - acc: 0.4641\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7185 - acc: 0.4642\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7178 - acc: 0.4646\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7179 - acc: 0.4650\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7170 - acc: 0.4646\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 2s 20us/step - loss: 0.7171 - acc: 0.4650\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "n_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n",
    "n_latent_factors = 3\n",
    "\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "\n",
    "prod = keras.layers.dot([movie_vec, user_vec], axes = -1, name='DotProduct', normalize=False)\n",
    "model = keras.models.Model([user_input, movie_input], prod)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=1)\n",
    "\n",
    "y_hat = model.predict([test.user_id, test.item_id])\n",
    "y_true = test.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7311717652906896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773522383374458"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3033334205107707"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2be50ef0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXd4VVXWxt+VRkjoJPQSmvQmEVAEKSoIjqijjug4Y2XGMuo4FpDRscvofI7Op45ixbGAjW9UmoAgIjUgPaAhIJ0EkBJKQpL9/XHPSc69Of2emqzf8/Bwc+4p6+6zz3v2XnvttUkIAYZhGCY8JPhtAMMwDGMNFm6GYZiQwcLNMAwTMli4GYZhQgYLN8MwTMhg4WYYhgkZLNwMwzAhg4WbYRgmZLBwMwzDhIwkox2IqDOA6YpN7QE8KoR4UeuYjIwMkZWVFb91DMMwNYTVq1cfFEJkmtnXULiFEFsB9AEAIkoEsAfADL1jsrKykJOTY+b6DMMwDAAi+tnsvlZdJSMAbBNCmL4AwzAM4yxWhftaAB+pfUFE44koh4hyCgsL47eMYRiGUcW0cBNRCoDLAHyi9r0QYooQIlsIkZ2ZacpNwzAMw9jASov7EgBrhBAH3DKGYRiGMcaKcI+DhpuEYRiG8Q5Twk1EaQAuAvC5u+YwDMMwRhiGAwKAEOIkgMYu28IwDMOYgGdOMowHHCwqxpyN+/w2g6kmsHAzjAfc9M4q/PH9NTh2+ozfpjDVABZuhvGAnYdPAgDKy3lxbiZ+WLgZhmFCBgs3w3iAENzSZpyDhZthPIRAfpvAVANYuBmGYUIGCzfDMEzIYOFmGA9gDzfjJCzcDOMl7OJmHICFm2EYJmSwcDOMF7CvhHEQFm6G8RBiVwnjACzcTKgQQqCktNxvMxjGV1i4mVDx9vc7cNZfZ6Pg+Gm/TWEY32DhZkLFF2v3AAD2HgmXcLOLm3ESFm6G8RB2cTNOwMLNMB7ASaYYJ2HhZhgPIQ4rYRyAhZthPIDb24yTmF3lvQERfUpEW4gol4jOddswhtEjrK4Hbm8zTmBqlXcALwGYI4S4iohSAKS5aBPDaBNCV8PJklKcLCnz2wymGmHY4iaiegCGAHgLAIQQJUKII24bxgSX4tIyjPznYnyfd9BvU0LBTweK/DaBqWaYcZW0B1AI4B0i+oGI3iSi9NidiGg8EeUQUU5hYaHjhjLBYfcvp7D1wHE88n8b/TYldISww8AEEDPCnQTgbAD/FkL0BXACwITYnYQQU4QQ2UKI7MzMTIfNZBiGYWTMCPduALuFECukvz9FRMgZxjfCOTTJMM5gKNxCiP0AdhFRZ2nTCACbXbWKYTQIo6eBXzKM05iN4/4TgA+IaD2APgCecc8khgk2J0tKbR/r1Crvy7YdQs6Ow46cqzqSX1iE299fjeLS6hnNY0q4hRBrJf91LyHE5UKIX9w2jKk+bNxzFFkTZmL3Lyf9NiVu5mzch26PzsWG3Ud9tWPcG8tx1WvLPLlWzo7D+PucLZ5cy4jFPxbi9BljMX54xgbM3rgfq3+unlLFMycZy1id+/LRyp0AgIVbwx9t9O2PkRDI9XtqTkTsVa8tw78XbfPbDGzdfxy/e3slHv0vRzOxcDP2CaPD2QeUszw5HNA+x06fAQDkF57w2RL/YeFmQklIZ7wzjCOwcDOqrNn5C04FcJp2TWmx/nTgOF5ZmOe3GUxAYeFmqrD/6Glc+epSPPTZekfOF0/j+A//yUHWhJmO2BEEujwyBweLig33u/LfS/H83K2mBuKqOyWl5ciaMBPvfL8dgDvhlcu2HULWhJnYc+SUC2d3nmov3EIIHD11xm8zQkVRcaS8Nu11NnLCTmN57qYDjtoQBLbuP264T/GZyILIYelhLNt2COXl7vivThRHwi9nbdjvyvkBYNqqyAD6qu3GIZZTl+7Atz/6O9Be7YX7gxU70fvxr7GtkBP9OEdNdjDX5N+uzoLcAxj3xnK8LbWInWL/0dMYNPkb/Hw4jjBSF27X377YhN+/vdL5E1ug2gv3wi0FAIDtPo5E5+w4jOyn5leMijtNcWkZnpuzxXOftL+NQW8ENK+gCK9/WzUUzqmJNNWBvUcjCzdvP+jsM/bftXuw58gpfLD8Z8vHWrk/UxZvc9x2t6n2wu0HJaXl+CRnV0UY2AvzfsTBomLDSRvTVu5EXoH1nsF/lv2MVxdtw6uL1AezluYdRGlZueXzBhGv5fLq15bi2dlb2NfsI7HuonwHe88nikvxzKwtWO/zhCqrsHDb5PSZMs3ptK8szMMDn67Hl+v3WTrnhM83YPRL31m25UxZ5AVRoiLOK/IP4bo3V+BfC36yfF6nkF9Gn67ebfsc+476M2jECyDo0/HhWZbS+366ejcWbS3Am9/lY+LnG2xd85eTzvVcy0MaV1rjhHvCZ+uxIDf+Aa8uj8zBoMnfqH5XKEUNHIsZFDVTR9TEd/LsLWg/0V5kRcHxiC3bfOwKrpQGfNbusj/b8PQZ53oMeQVFjrbajLAjDSIkvvRSiwOS93+yDje+swpPzcytmFELAOt3H0HBsdOqx/jplhJCYPqqnSgqtp+fxg1CIdxvLM7HivxDjpxr2qpduGVqjiPnOlhUglunrsLIfy525HxavPbtNsjPh5lQMiNOFJeizMQDFyTpcHKNyQtf+BbD/+dbi9eP+duj0qkpvvTLXv4eI16wdk+cwOgurtx+GA99tkF1mv2ybc5okh1CIdxPz8rFb6Ys15yQkLPjMLImzLQdvrbv6CkUHFd/2xsxP7cAWw8Yh3c5wdxN+5H91HwsjXPJsO5/m4v7P1mns4e2WMzbfAB5BcEZyLnl3VV4dlau7j4niksxfdXOKuK/bNuhikx/+4+exsc5u6ocWzUcT19I520+EPf9CSvxhi4eP63eqvUzJPKkNLZxqKikynfj3ljutTkVhEK4ZZ6fu1V1+9ebI66PJT9FHphnZuXiha+3orxcYIEUVaLHuc9+g/5PLwAAFBWX4r9r9zhkcQSnKp6cxnOj1gtKp/mwL2ZiwYwf7P3G297LwR/fXw0AIJUfVnDsNF5ZmGeqhfzCvB8x4wdtv/fOQ9phYPLpF2wpwOuL83Wv89gXm/DQZxuwPD86RnfcG8vx4KeRSUa/fWsFHvx0PY7a9J8eLCrGkZMluO29HFz35grjAxjXmLf5AJYpeuinz5Rh456qz8zJklLc/M6qqG1VelJB6nYqMLvKu2csyD2Ac9o1Qr3UZNvnmCI9yI3SUywfO+Gz9fhq/T50bFIH3VvUr/J97r5jyKxbS/ccXo93mHkxrNl5BHkFRejYpI7ufrdOXYX5ucYvOy3unvYDlucfxpBOmejZqmr5KZEHTK/o20r1+yHPL6yyTe1lYYTsXlLLoy0v5CvvUy4EOk2ahav6tcazV/ZUOZv6zc1+ar5lu+xSeDzaXVZw7DQKi4qj6uuwfyxC56Z18doN/Tyzy269P3Kyams2Hm57L9oVOmnGRny2ZjeWTxyBZvVTK7Yv3FKIHJ20r6fPlFXM/9CrdgXHT+NQUQm6Nq8Xn+EWCFSLe8+RU7hlag7u+egH08fsP3oaufuOqX732JeVC/XE1qkz0iBgbKXZJ8WkasVEX/LSd6YfUrstbS2XUOyDsW7XETz2xSbTD4yZ6bzxiDZQWW5lGkbd8NaKKlPYsybMdPzhVSKL/S1Tc0wtgnCmTEQNnAFVW2Ky7/nIyRLDGGCnX+TnPB1d/4Y8vxBj/rUkatv2gycwZ5P+TMNVOw7jlxOV5b7z0ElPB21ljMZb4u2xrt0VEefj0jyKhVsKdHt6Mn+evhZPzdR3wxWXlqH/0wtwiY1osHgIlHDLD73eTCkhBB76dH3FYOXAZxfgu5+s+xQ7TZqN1T8fRp8n5ql+b2cQcNDkb3D5K99rfi8gcNeHa9Dt0Tm659FyCcnIonHN68vw7tIduqt8KB+J0rLyKtP/fzxwHFkTZmpG2hw5WYJ+T87DOpWIkBM2Rtq17tWmvceQNWEm3l5ibvZd7KN+7PQZZE2YafhALs2LHlAyEgWjwcELX1iMYf9YpH+SGMykYLAi9kYRNwu3FCBrwswokQaAq19bFuWnHfL8Qt1B2/W7j7i+GMadH67BTe84OytRfnEfLy7FfR+vxU3vrsKfp6uP8Sjv9/eKsQqtWvDKQn/ylAdKuM1QLoDpObscGRhYuT26m5Q1YWbFihl/fH+NpXMVFZdiz5FTWLvrSJXWmpKv1u+LOzb46Vm5qkJqxL3T1qL3419HbfthZ+T3zlVrnQlgef4hHDpRglcX5eHlb6JjweXeiRpWo0Dkc01fVXWAUInWAyT7w99YXFX4lcfcGtONls202yq284K/4wPzdcuJ8ZHXF0fEJXf/MTw8YwN6/m1uxXdbDPKm7FI0oi57+Xuc//eq7isZJ2yduX5fxYIbckP8o5X6dcIsby/Zjs/XODt+ddTFnqIeARPuqk/PvM3OJBn6+dAJ3Do1eiBioYmBy1MlZbjv47U4ZPCA9lA8DGZ48qvNWL9bW3xLSstxQCOuFQDGvvI9iksjLS2zonPcRgtZee5/fP2j8QEuhQDE/sTiM+WqkUBW9fd0aVlFnDmgbX63R+fivulrsWmvulsulqwJM/EnyeUXpERRH67YaakeDH5OW6itojUBS2vcwspyabsOn8SX6/aqn9/0WbSxM7biJqaEm4h2ENEGIlpLRM4EQetdT/E5dqDBLk/NzK3iv11psNjqNa8vQ98nv8bna/aYEy0N1Lrbby3ZjqsVawbGtngf/HQdBjyzACWlld1gI1ESQNTU9lMlZZqTGkxByo/uVtzYFrpaFICSm6euqogEAirFMXffsSrLbOk9cz8fOolrXl9myn3x+Q97KqZG//X/NhhOg/9y3V7sO3oKm02KvRr/mLvV0Rh2Gb1zrtt1BMP+sciRSSe7Dp+syBqoFYK6JM7wSSEEBj+3sOJFaRa1ehGWmbJWWtzDhBB9hBDZrlkTMFZuPxzXjD1Z7A6dMO5O/eE/q6P+ltOZfrVevRWh5L1lOwBEcpZ0nDQbWRNm4tapObj+zeW6gytLtx2s8NF9nKPeGnpn6Q7D66sRr9Rc+r9LVLfLD5vyhQZEv1jiWdj2sIl7BUS68Wam8J/77Df4q8qU8IVbC6IG5QqOncYbi/OrCOrri/Oxzqk8GiZvyvNzt2L7wRMVbrRYNuw+aiop048HjmPwcwt1wzVPlpTibhXBNZuDXQiBdhNn6e5jpbH88IzKafjHNOLKg0CgXCWxjYCZFnN9BDTkUjPqxQwvmcgxIuduOKVoAc7PPYA1O/X94Ne9sQI7dQaC8wtPRLkRtCgvF5j4+QYszTsY1S7ff/S0aSGUERC2Fk7QfzjNP7kbLbSO1QTZLDe9swpvflcpaHd8sAZPz8qtyOuijMoxctMZYbe3dKJYvfX5q5eXqA7IytdZ8tNBbNxztCJCZeV27RmG3R615mKMxWgCsPJrsz2f8e/lmM7hv/sXf3LomI3jFgC+JiIB4HUhxBQXbQIRYXn+Idz5obUBwuqOn/lw9IRx496j+GjlTny0cif6tG4AACg6XYqBry5AYoI50QiKD/FvHq4gvksRoSHHE2/edwydmtaNute3TM3BjsljAETCKa2w/+jpinTCz85W74mcPlMW9QKXGwDyRCstYsP45m7ajycv74HfWrTRDlkTZuLCrk3w+g3GDgC5LPNN5uv5evMB9F2hHWCgxMwEPzcwK9yDhBB7iagJgHlEtEUIEZWgg4jGAxgPAG3atInbsNgETbG4tNiGDqIi9tvSUTpqa1WrnE5UH4vdFUzUfqLsHzWTEyVyDuP98guLsPeIRiKimLLcc+QU6tRKQv3ayZbKOTbz3CkX07mq/eTFPx7E2D4tNY+xGvo68NnKcYANinED5bUf+mw9/ru20iW3WmdSipLY3lTB8fjz6Fhhfm6BYXa/6x2axRqMZkUlplwlQoi90v8FAGYA6K+yzxQhRLYQIjszM9NZKxUoC/BCD5PS7Dp8SnPUWo93FT5iNRErKi5VHQSSBcPLVrbeQ6Anfsrv7E6keUCael6k4Vf8at0+DP+fbzUnEU1dGp1sf9Dkb9D3iUjoY9AeOhmnb+1nNtPmKkXbCmputLs0eslmXwZW2RFH1kun60XXR+Z4ln7YsMVNROkAEoQQx6XPFwN4wg1jlBVZq6X21YZKv7faogNdH9Gf3GKXJXkHLY9+E0XHJd8YkxcBsB5G6Cbv2hiIfHVRHjo3rVvx9w6d/CJK1AakgMrVVGL553z9qB612PlyAdcnjMSD2ntSQNiO5vjLJ+vQulEaehmkGnAKNVfmVxrjUr/+91K3zbHMCp3xm+0Ho7XFTK/t1JkyzM8twA0D28ZrmiFmXCVNAcyQfJBJAD4UQrijjhJ5BUV4dZH6jCStBx6I5K0OEgT9CQ5O5ph2Ar0IlCUaXfTn5myt8Gtb4QsbvRc7nP/3hRjZvanNY9XzrTuHwDOzcnGW4sX3+Zo9+EFjUNnMNO1rXl+GNo3SDPdr/7B+JIaT6A2Ax8uDn623fazePAmtKCtDPOoiGwq3ECIfQG8PbIkiyC0ls0ywucKHEjcrvRWshkaFdGGRKNyOGBCiMiGaEq1Qu2+2mFtZPCh1Rmabi+u9ar3knCdYDrdAhwMy4SCelW1qMlbru50xlprGNJ10E7FYcUnNzz0QNf1fC68kLFDCnfOzccwww1hFnswUNOZu1s/ex1jHSi/X6sLcZqb/x04Mc4tACfekGZUxtE4uCMp4T1jWTPSTIw7U8dsNYq0ZbZwo/1iM0sA6RaCEm6k+3PWhtbwRjD1mb+RWu13sxOh/aHJijtuwcDNMCPAqCofRR5nLxE9YuBkmBOiFwTI1DxZuhmGYkMHCzTAMEzJYuBmGYUIGCzfDMEzIYOFmGIYJGSzcDMMwIYOFm2EYJmSwcDMMw4QMFm6GYZiQwcLNMAwTMli4GYZhQgYLN8MwTMhg4WYYhgkZLNwMwzAhw7RwE1EiEf1ARF+5aRDDMAyjj5UW9z0AvFmXh2EYhtHElHATUSsAYwC86a45DMMwjBFmW9wvAngQgDdLGDMMwzCaGAo3EV0KoEAIobucNBGNJ6IcIsopLCx0zECGYRgmGjMt7kEALiOiHQCmARhORO/H7iSEmCKEyBZCZGdmZjpsJsMwDCNjKNxCiIlCiFZCiCwA1wL4RgjxW9ctYxiGYVThOG6GYZiQkWRlZyHEIgCLXLGEYRiGMQW3uBmGYUIGCzfDMEzIYOFmGIYJGSzcDMMwIYOFm2EYJmSwcDMMw4QMFm6GYZiQwcLNMAwTMli4GYZhQgYLN8MwTMhg4WYYhgkZLNwMwzAhg4WbYRgmZLBwMwzDhAwWboZhmJDBws0wDBMyWLgZhmFCBgs3wzBMyGDhZhiGCRks3AzDMCHDULiJKJWIVhLROiLaRESPe2EYwzAMo46ZVd6LAQwXQhQRUTKAJUQ0Wwix3GXbGIZhGBUMhVsIIQAUSX8mS/+Em0YxDMMw2pjycRNRIhGtBVAAYJ4QYoW7ZjEMwzBamBJuIUSZEKIPgFYA+hNRj9h9iGg8EeUQUU5hYaHTdjIMwzASlqJKhBBHACwCMErluylCiGwhRHZmZqZD5jEMwzCxmIkqySSiBtLn2gAuBLDFbcMYhmEYdcxElTQHMJWIEhER+o+FEF+5axbDMAyjhZmokvUA+npgC8MwDGMCnjnJMAwTMli4GYZhQgYLN8MwTMhg4WYYhgkZLNwMwzAhg4WbYRgmZLBwMwzDhAwWboZhmJDBws0wDBMyWLgZhmFCBgs3wzBMyGDhZhiGCRks3AzDMCGDhZthGCZksHAzDMOEDBZuhmGYkMHCzTAMEzJYuBmGYUIGCzfDMJ7RskFtv02oFrBwMwzjGV2b1/XbhGqBoXATUWsiWkhEuUS0iYju8cIwhmGqkpIU7raWEH5bUD0wUwtKAfxFCNEVwEAAdxJRN3fNYoJGn9YN/DaBAVArMdzCzTiDYS0QQuwTQqyRPh8HkAugpduGMcHi9Rv6+W0CA4AbrO6R3bah3yaYxtLrm4iyAPQFsMINYxiG0Uewr8E1GqWn+G2CaUwLNxHVAfAZgHuFEMdUvh9PRDlElFNYWOikjUwA0NOLK/oad8Cm3NAvVA9GdeHxy7r7bUJoIIr/HJ2a1In/JCYwJdxElIyIaH8ghPhcbR8hxBQhRLYQIjszM9NJG3Vp0yjNs2s5yQe3DsDtQzv4bQYAYEC7RnEdb9b/fcFZ3tWLMHF1v1am9yUn1IUJPWaiSgjAWwByhRAvuG+SNcJajwd1zIhbMJ0i3kgF7r7Hx7kdGpveN+hl3aJ+Kt67ub/fZtiCoC0mdWsleWiJMWae2EEAbgAwnIjWSv9Gu2xXoOnWvJ7fJgSWl67t47cJlrn2nNZ+m2Aaq7LtdcNmxp2DMCTAPav6tZM1v9Mrq6C9Ls1ElSwRQpAQopcQoo/0b5YXxpnBSjeT0aaORouiab1ahscqK/XYPtr+7qC2Fu8e0Ul1+4u/Cd9LSMm4/m08v2bTeqmeX7MmEvqg0DuHdcTgThmG+/1peEcPrKl+3HvhWQCABmnaLZWA6nHc6P1mv0hLMd9lT0oIqR/RRew2HoJWkqEXbiIyVUH/eIHzA4EZdVKQ9/Qlto8Pg96N698GOyaPQWpyot+mMAAeGHmW6X1FHDXsnRvPsX1sTeE8C2MTThMsj7uLOCmSsi8sgQhJPJMNAPC/4/qiqLhUd5+gRkS4bdb5HTOwJO+g5vf9LQxSW2lxd8isg+4t6pveX8mwLk1sHWeEWlknEFAegFaMVR+3n+GtrDpx4IcOqcWJZtQx9kO7iQDwq94tXPOppqX409p3SkteM5h12qqhfkhruo3ff1nvFrjxvCz082k2YGxrNKux9m80Kme/fkOQqRbC7fXL2s+GY/vM9Crb4m30Z7dt5PrAYYs40nm+f+sABy0xR2ICOVax4i3bVX+9sPJcJo85u00DV3o4zeqlag7mKpl6c39TY09eo1V+yYmkGw4YtIH1UAv3lSoz9s5tr+53crLg9W5wGPFi4LZHS3tddgBobdAijRe1+2lnxmGKS26ztJQkvHxdX3zgwwssluUPj8B9Fxn72ZMTE0y7afzQxNi8JLPvGay7v9pL0E/XX2iFe/59F+CFmHCtl67tg6khDf6Ph3grfkKc0QdaL8tYzL48aykmBP3zN72RWdc9V1DX5vXQuE5VX2Xd1Ghf8oe3GYvmgPbuTai6tFcLDOqY4UmToX+Wez2wIDRcd0weg09vPy/q745N6upORLt7RNXGjZ/Nt9AKtxK5MtRLTfYkX3Hsi/a/dw5y/ZpOELv6yKvXn22q22tEtxbRE5KcmGXWQXIJXdHXvTj9X/Vugdn3DEayiZbyeR2Mu/1aohS7uVOTOujcNJgLCmx/djSm/2GgI+dSRrXE0zrVO9LJlBePXtoN44e0V/1Ob+KOH1QL4faa7LbRLaverRvgM8Ub3Ata1Lc+0eHdmypDvL75ywUY3bO5brf38j4tbNk2+97BePvG7CrbrTy8n98+yLD7Gg+pyQl4yeEJNvVqm3thTRzdBXP/PMTRa8didyIMEQU2+kcNs8L9B0mQE3R+W8P0FDw8uqsjdrlNtRBuM/XMyZb4bUPaVdnWr21DnNW0asSH1oxEAEiLIzZ6oqKCmfn9f/91T3RStPLaZxpnMXvx2r62bGvVMA3DuzS1dSwQ+T3105LR1cXUAsmJCYYuIqtx0OXl8VjkLKN6NPPbBFzczRkb5LsQTw6U2yThduudNKZnc3dOrEG1EG49v1n+M6Ox+YmRqJWUqNkNsoLeFHC1QS69etK/XSNMvrKnrclByYmVZ3bDb/ifW/wbK/DCD+rG86tscevFZpuJsNFyYZmNzvGq1fzAyM6a3zkRxvfMFT0rPquFhXZQibJSQ6+lbRflKe+5MH6XoxVCK9yq90EtuD+BKiYtPDy6K96/RX2QadH9Q01dV9kFjTe6hIhwbf82qFPLfMvbbVFLlFqhvVoGa6mydhnmHlCnEML6/X3k0soV/fQiQLo0M+5JNNSYbt+vbUN8edf5AIBWDf1fMf1357a1tH9HlV6pFj1a1sN1A/TnBrRulIZXrjtb8/v+WY3w1OU9qlkcWIiF22myPBaG+HGnKvoRr/rq9doPnsycewdj8xMjXbdlrMKvb9VVUjc12ZP8ID1b1cfmJ0Zi/n0XOHK+C7vG49ay9nuvyW6NG8/LMrXvk2N7mNpPb4JWu4x0/HZg24qUDSNMuPAu7ma/PLyiWgi3lcfL6nPVq5X9+GOzZGdVdqsTHXjwP7rNelTA81f3RvvMdEtTqp2gbq0kjO7ZPGpikZoW1EpK9Ny2IJOWkuRY/hi18nbr/U2oXHjDSPP7tqnqapETf/XPshZ6WTslEcsnjsDkX/c03jkEBFa4aycn4iKLbz4zkjegfWPcNrjq4KIWaqFidip19xba3eOB7Rtj0+MjsWPyGAy1kcs41hy1xPxG4WyjezbHN38ZavnFZoW7hndEl2bqYXDDOruTG8Nr5FV+lMVop77I9S42hNMN4hFpOz00uSdzWW/rUUsL/zIUi+4fGjWhq55OqJ6y19Ssfqqp0E811NxbHMftIYkJhEljKn2Rgzraz/Cl1WJQi4a4yiBveLrJ2Ge7z1jrACzx1iGzDubcqx4G99CoLvi3CZeJl9gRtFeuPxuL7h8ad/IxeTBtyFnBmzaupG5qMmpbaPkri1R+fKxEZDRMT0FWRnrUs+fWjFUlvVs3QI4i9YDfBEq4F94/FDPuiMRDW3GdxeOXfefG/tjw2MUWrqX93YTRXdAoPQVtVUTS6a5nGEJt52qItBopSQm4oLPcWvX/xwkIW+Kbmpxoa7zkibGVU+xX2xQIrbj3dY9ebCoBmN2VnVKTjctJ647+8MhFeDFgqyZpPap+J3NTEijhbpeRjrMUscZWxU4eKJEL2MxU7JSkBNRNdWZW1LDOTbDmkYuiKrJVvQ7AjGDH6KzhFnESM4mMrGQXVAqM3JKMO57cxE2V464z6tRCY5sCoWVn/bTkqDQCamx8fCRm3OntJDKBSAvarvui8jzaBWynEXCTNHhq5KYareildOCJAAAR50lEQVQpyBE+XoUFVsvRni//NAhb9x/HUBf8pm0ap1VEDjRM8y8frxI/8z842fJ363fMuWcInpq5GV9vPmDreCvhml4z597BGPXid3GfR2+imNMEoUelh+wzr187GXuOnFLdZ8fkMVF/p6UkVdnmJoEWbj1R0Lv1zevXRvP6zgzqxF7nnhGd0KReKp65oidGdFV/MSj1x6obJ94qffOgyMDrsonDceTkGZwpK4+7RaOHFf+mWZx2A7VpnIYxvZrbFu4gYyYm3G2shgTqtZDr107G0VNnovL//OPq3vjXgp/Qu3XVuQVGj1c8qwAFGUPhJqK3AVwKoEAIYS6w0gHstL68eI/L4XpGEwNk5ErtVPXRK5eVk0agSd3IBCEnX156xFvmbvk3aycn4tSZsirpO2UmXGI/J0W/tg2x+udfDPe7e3hHZJjNbKiVoMqhiqOvrVUv4oXcqZlUp1YSjp46E5WxsV1GOv4Zk1cm2G129zHT4n4XwMsA3nPXlAjKChaEFJDxIv8cZcv7rd9XTcBk97zS2eM+n5ekpyTiREkZkhIII+KY/AFE1hL97qeqy4K9dG0fDO6UiaTEqo+4mS6tENq9pQ9uHYATxaXo99R83XPcd3FkOviRkyWG15OR67/TvQ433RNBW2SgJmDYhxZCLAZw2ANbpOt5c4xdnLiWW4N2fvgOjbrJM+44D6/9NnrprnelZEFNYlqjdop2UEf1wcmLuzdD7ZREy24i1YT5MeWampxoewCRYZwgUFElSoistzqCEiKnFHcvo0qC6M/r26ZhlUx1RomSAnIbDVk+cURFBNPdHqwi5CU1uRV9VtO6GNi+EZ65MrizLB0TbiIaT0Q5RJRTWFjo1Gk95fahHVzLNeHUc9BcysNdJ2qFlrBIXTRhl4Zm9VMrFm8eqBN6WoM1UBW98rhjWCRTZuN08z0avfPZSQuQkpSAaePPrZiaH0QcE24hxBQhRLYQIjsz0/q0bfVzmtuvRYOImJmdfajFQ6O6IO+Z0XGdIxY1SdX7XUYSPGlMV7z4mz4xMerhUgat31iTW3luo9cbNSr2RxVZD+0yrEskAquBYnq6mlvq+gFtsWPyGNQ2GXtv1MvUSzsbZgLrKrHC45f1wMvX9cXZKklptOjavJ7lXChmiWcCjhq3nl+ZWyU1ORGX921pyhdrhw9vG4jfndvW9GoubmAmvGzrU6OwctIIR88JAFdLqQnOMZnEyCn3lDxLU+5RyWteNkz3d65AYgLhZkX9s8vES7pg+cQRjo0NmLmdvVrVd2xyXdAwEw74EYChADKIaDeAvwkh3nLbMCvUTknEpb2sJawxuyyWncdy0phu+Dhnd+T4kLUie7SsH9eK7F5RKykRTepayWNu7j6c1zGjIupEa/KFKnotWhOHN0pPwf+O61uRIGx0j+Z45opS/LpfS/M22EQ1O6D8nUPXSEpMQDMby+2ZIShjW15iKNxCiHFeGKKGXzckJTEBJWVa61AZP4b1ayejQVoyjpw8ozgqXAJulnhuUayWBraEPKqHv1Jky0tIINNzBaxyRd+WmPHDHt195HsT7zP4wa0D8OOB4/GdhKlC4FwlyodXTtZUL9XbbvvcPw/B9Q49NBUTcJSRJg4rlNeN+hsGWlv1JBYjMaiBDSjXOU+R6renhz2qQR0zcNOgaFeLvIpUVuOwLV4SHAIn3DKEyqTpN1hcHile2mWk4/K+LSvs8BuzrR6veihPXu7ZBFrH6djE/NJZ1Yl4JzrFcmmv5nhoVBdbxw7qmIH3bxmAuxwIoYxttGQoZlzeMdT6Wq5hIdC5SuQY2cwQT3Zw08f9hyHtMXvjfpwoLnXtGoZ4/GabPn4g8g+esH281kIObhL0cQ4184xcey8r1nmU97SywPT5JrI66qE22JxRpxYW/OUC9H78awDAqB7errzuJYEW7muyWyOtVhLG9GyOx77c7Lc5lpCrldO5SpRMHN0VE0d3Rb8n57lwdn3kZEDXD3CuN2RG3wa0b4wBJtL1xuLEquf3X3yW6VXWg8iLv+mDHi3rY/GP5udZWIlU6tHCn0Ftud40r5+K+jqr4VQnAi3cCQmkubyREw+iF1TmKnHvGn605xqkRYT7N+e0tn0OzVZdQG6t7KqTJ9ncNdybXMtuIbv/rAh3mAiJJDhCoIW7uqLXDdVaP290z2Yo1wp0kQhLvQ16PmaZLs3q4cNbB+BsjQyDAJApZWPUS29by4XUt0EkKA6h7LYNUeSn+9ADAifc8pRzL1ZPsUMzk6lSn72yFybPzsWZMoHjMZVIr/X9+Nju+KngODbuORa1/dXr+2kc4Q+uSG9QnnwF52kksZJ55ooeGNwpQ3VFcpk6tZIw994hGPniYqfNcw0rPUQ/XsOp0oo+KSor+3x6u7cr+fhB4KJKUpMT8dFtA/HOjeYHOrxix+QxplcKGdWjGRY9MKwif3cbk4v11ktNxm2D20dtC6JbyE2NdfPXOm133dRkXJNt7C4KakMEMCiT4FU9AMDtQzvi7uEdHR1jCROBE24AOLdDY9RPi3YZTBs/ELPuNjfbMYh0b+HeSiXyNOlElxJk6eHkBBw3Caj+BJ6gllvtlETcd3Fn1RZ3TSBwrhIt9LKvBRllY7lt4zT8fOik462+d2/qj2X5h9AgIGtgGqHVgaius0sZxmlq5uvKJ9xqvWTWraUZfeMWbraWg+gaYoJLTXzdh1a4+dEOBqyx4aNBjBvSaurhoFKTqmJoXCVe43g+ERvHDO6UgTNl5bjFgbSaQcQXbQihIFnhnRvP0UmQFuHyPi1x38frTJ3PzIu5mhdpIGHhNiDeFqV6a8ZcVW+YloJ/jesbnwEBRHshBRevWUOaY/KCBXokxAxiqxW7nfGGmlDEL1/XNxCzM1m4PUII4er0d7OM698GrRoGe9p2TRFZP/nduW1RVFyKz9fop3cNy2Qpr7Ca998tWLhdRjnQZvYRcLPl+WyAF0BlvOOJsT2wIPeAoXDLtM9MR36h/eReQWTZxOE4WVLmtxm2YOH2CDtaHOSWpxuhe+wrDQ6xjYdZdw9GaXn1ukPNTc6CDiIs3C4TYO11BDtdaXly1d0j1JM2uTtzsnqJj9vIjQc7q6V7RdDT5rpBaIU7yK1RI2pgPYuiVlJixbqOXsG+Wm2qjfCFWRQsEto47lBSjepVdXnWazI1SOeqHaaEm4hGEdFWIsojogluG8WEBycf/mrT8qsGyHlvOmTWzKXego6hq4SIEgG8AuAiALsBrCKiL4QQ4VqSxmdYk8zjx5T3pASqdoNv8ZCanIh3bzoHvVo18NsURgUzLe7+APKEEPlCiBIA0wCMddesaoRCg7pLSzul1wruQI9ZHhjZGUAkT0pQ2DF5DCaN7oo3fpdd5btaUha59BT1tsqaRy/CmkcuctW+sDG0cxM0SjdOXPb8Vb3RuWldzUVAGOcxMzjZEsAuxd+7AQyI3YmIxgMYDwBt2rRxxDg/kfNut26Yhn+N64tDRSVxn/O5X/fCjee1NQxDurh7Uwzv0qRCHIPCHUM7YO6m/QCAsX1aYmyflo6eP10q86v6tbJ03DXZrVA3NSIatw1pr7rP8C5NMOGSLrh+gHrdrJfKomOXi7o1xUXd4ltFPqtxWqjX8/QaM8KtOmu7ygYhpgCYAgDZ2dmu9zmTEt0dV+3Woh7e+F02BnVsjLSUJEdiPmunJKJf20aG+6WlJOHtG8+J+3pO8+CoLnhwVBfXzp+anIgtT45CisV7+9xVvQ33SUgg/PGCDnZNCzQXdWuK3b+csnxc64aRxT2CkDJ50QPDbB/btF4kH/3QszKdMqeC0T2bYd7mA46fN17MCPduAMolPloB2OuOOcbk/PVCLNxSgJYevJ3jbUUAwC3nt8OkGRvRtF5wXApBJsjxwk7z3zsHoVZy/A0QNdeQGTo1rYslDw3z5FlykxYNamPlpBHISHf+GQvakoEyZDSST0RJAH4EMALAHgCrAFwnhNikdUx2drbIyclx0k6GCT3vfr8d57RrVDHWwYSfA8dO4/jpUnRsEn/0DRGtFkKYegsbtriFEKVEdBeAuQASAbytJ9oMw6hz46DqmZ63JtO0XiqaurcqoSamZk4KIWYBmOWyLQzDMIwJeOYkwzBMyGDhZhiGCRks3AzDMCGDhZthGCZksHAzDMOEDBZuhmGYkMHCzTAMEzIMZ07aOilRIYCfbR6eAeCgg+Y4BdtlDbbLGmyXNaqjXW2FEKYSrrgi3PFARDlmp316CdtlDbbLGmyXNWq6XewqYRiGCRks3AzDMCEjiMI9xW8DNGC7rMF2WYPtskaNtitwPm6GYRhGnyC2uBmGYRgdAiPcRDSKiLYSUR4RTfDgeq2JaCER5RLRJiK6R9r+GBHtIaK10r/RimMmSvZtJaKRbtlORDuIaIN0/RxpWyMimkdEP0n/N5S2ExH9S7r2eiI6W3Ge30v7/0REv4/Tps6KMllLRMeI6F4/youI3iaiAiLaqNjmWPkQUT+p/POkY00tO69h1/NEtEW69gwiaiBtzyKiU4pye83o+lq/0aZdjt03ImpHRCsku6YTkfEKw9p2TVfYtIOI1vpQXlra4Hsdq0AI4fs/RBZo2AagPYAUAOsAdHP5ms0BnC19rovIKj/dADwG4H6V/btJdtUC0E6yN9EN2wHsAJARs+05ABOkzxMA/F36PBrAbETWBh0IYIW0vRGAfOn/htLnhg7er/0A2vpRXgCGADgbwEY3ygfASgDnSsfMBnBJHHZdDCBJ+vx3hV1Zyv1izqN6fa3faNMux+4bgI8BXCt9fg3A7Xbtivn+fwA86kN5aWmD73VM/heUFnd/AHlCiHwhRAmAaQDGunlBIcQ+IcQa6fNxALmIrGivxVgA04QQxUKI7QDyJLu9sn0sgKnS56kALldsf09EWA6gARE1BzASwDwhxGEhxC8A5gEY5ZAtIwBsE0LoTbJyrbyEEIsBHFa5XtzlI31XTwixTESesPcU57JslxDiayFEqfTnckTWbNXE4Ppav9GyXTpYum9SS3E4gE+dtEs67zUAPtI7h0vlpaUNvtcxmaAId0sAuxR/74a+iDoKEWUB6AtghbTpLqnL87aie6Vloxu2CwBfE9FqIhovbWsqhNgHRCoWgCY+2CVzLaIfKL/LC3CufFpKn522DwBuRqR1JdOOiH4gom+JaLDCXq3ra/1Guzhx3xoDOKJ4OTlVXoMBHBBC/KTY5nl5xWhDYOpYUIRbzb/jSbgLEdUB8BmAe4UQxwD8G0AHAH0A7EOku6Znoxu2DxJCnA3gEgB3EtEQnX29tAuS//IyAJ9Im4JQXnpYtcOtcpsEoBTAB9KmfQDaCCH6ArgPwIdEVM+t66vg1H1zy95xiG4ceF5eKtqguauGDa6VWVCEezeA1oq/WwHY6/ZFiSgZkRvzgRDicwAQQhwQQpQJIcoBvIFIF1HPRsdtF0Lslf4vADBDsuGA1MWSu4cFXtslcQmANUKIA5KNvpeXhFPlsxvR7oy47ZMGpS4FcL3UNYbkijgkfV6NiP/4LIPra/1Gyzh43w4i4hpIitluG+lcVwKYrrDX0/JS0wad83lfx6w4xN36h8iixfmIDIbIAx/dXb4mIeJbejFme3PF5z8j4u8DgO6IHrTJR2TAxlHbAaQDqKv4vBQR3/TziB4YeU76PAbRAyMrReXAyHZEBkUaSp8bOVBu0wDc5Hd5IWawysnyAbBK2lceOBodh12jAGwGkBmzXyaAROlzewB7jK6v9Rtt2uXYfUOk96UcnLzDrl2KMvvWr/KCtjYEoo4JIYIh3NIPGY3I6O02AJM8uN75iHRP1gNYK/0bDeA/ADZI27+IqeCTJPu2QjEK7KTtUqVcJ/3bJJ8PEV/iAgA/Sf/LFYAAvCJdewOAbMW5bkZkcCkPCrGNw7Y0AIcA1Fds87y8EOlC7wNwBpHWyy1Olg+AbAAbpWNehjRRzaZdeYj4OeU69pq076+l+7sOwBoAvzK6vtZvtGmXY/dNqrMrpd/6CYBadu2Str8L4I8x+3pZXlra4Hsdk//xzEmGYZiQERQfN8MwDGMSFm6GYZiQwcLNMAwTMli4GYZhQgYLN8MwTMhg4WYYhgkZLNwMwzAhg4WbYRgmZPw/rBMQntqUBIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(len(y_hat))\n",
    "plt.plot(range(len(y_hat)), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4.1810427, 5), (3.7510118, 5), (3.3734493, 2), (3.791001, 3), (4.206919, 5), (3.2825694, 4), (1.7857158, 4), (4.0701256, 4), (4.1192484, 4), (3.445529, 3), (3.4736178, 4), (4.0720267, 5), (4.1486635, 5), (2.9359403, 2), (3.4940045, 4), (3.5713542, 5), (1.2732297, 2), (4.4180975, 5), (3.3769302, 3), (2.5889719, 2)]\n"
     ]
    }
   ],
   "source": [
    "print([(i, j) for (i, j) in zip(y_hat.ravel()[:20], y_true.ravel()[:20])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.user_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.966648</td>\n",
       "      <td>-0.919319</td>\n",
       "      <td>0.863690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.437029</td>\n",
       "      <td>0.595531</td>\n",
       "      <td>0.467666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.826557</td>\n",
       "      <td>-3.698236</td>\n",
       "      <td>-0.893432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.669403</td>\n",
       "      <td>-1.374091</td>\n",
       "      <td>0.543034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.986767</td>\n",
       "      <td>-0.938171</td>\n",
       "      <td>0.853226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.254426</td>\n",
       "      <td>-0.479760</td>\n",
       "      <td>1.189773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.585588</td>\n",
       "      <td>0.943812</td>\n",
       "      <td>2.546664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2\n",
       "count  1683.000000  1683.000000  1683.000000\n",
       "mean      0.966648    -0.919319     0.863690\n",
       "std       0.437029     0.595531     0.467666\n",
       "min      -0.826557    -3.698236    -0.893432\n",
       "25%       0.669403    -1.374091     0.543034\n",
       "50%       0.986767    -0.938171     0.853226\n",
       "75%       1.254426    -0.479760     1.189773\n",
       "max       2.585588     0.943812     2.546664"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.107262</td>\n",
       "      <td>-1.108085</td>\n",
       "      <td>1.168447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.542848</td>\n",
       "      <td>0.566582</td>\n",
       "      <td>0.434296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.155398</td>\n",
       "      <td>-2.504371</td>\n",
       "      <td>-0.698575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.756104</td>\n",
       "      <td>-1.505675</td>\n",
       "      <td>0.913075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.093890</td>\n",
       "      <td>-1.167027</td>\n",
       "      <td>1.184544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.452147</td>\n",
       "      <td>-0.781497</td>\n",
       "      <td>1.469406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.098990</td>\n",
       "      <td>1.435501</td>\n",
       "      <td>2.481169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2\n",
       "count  944.000000  944.000000  944.000000\n",
       "mean     1.107262   -1.108085    1.168447\n",
       "std      0.542848    0.566582    0.434296\n",
       "min     -1.155398   -2.504371   -0.698575\n",
       "25%      0.756104   -1.505675    0.913075\n",
       "50%      1.093890   -1.167027    1.184544\n",
       "75%      1.452147   -0.781497    1.469406\n",
       "max      3.098990    1.435501    2.481169"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]\n",
    "pd.DataFrame(user_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Item Prediction\n",
    "\n",
    "- In online transactions or groceries transactions, people **do not** purchase 5 simiar items\n",
    "\n",
    "- However, they buy the items that are related somehow into each other\n",
    "\n",
    "- For example, a shoper wants to make Spaghetti at home, so he/she buy: Pasta -> Tomato Sauce -> Mushroom -> Parsley "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for next item prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM with Variable Length Input Sequences to One Character Output\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# define the raw dataset\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create mapping of characters to integers (0-25) and the reverse\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "num_inputs = 1000\n",
    "max_len = 5\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(num_inputs):\n",
    "    start = numpy.random.randint(len(alphabet)-2)\n",
    "    end = numpy.random.randint(start, min(start+max_len,len(alphabet)-1))\n",
    "    sequence_in = alphabet[start:end+1]\n",
    "    sequence_out = alphabet[end + 1]\n",
    "    dataX.append([char_to_int[char] for char in sequence_in])\n",
    "    dataY.append(char_to_int[sequence_out])\n",
    "    print(sequence_in, '->', sequence_out)\n",
    "# convert list of lists to array and pad sequences if needed\n",
    "X = pad_sequences(dataX, maxlen=max_len, dtype='float32')\n",
    "# reshape X to be [samples, time steps, features]\n",
    "# X = numpy.reshape(X, (X.shape[0], max_len, 1))\n",
    "# normalize\n",
    "X = X / float(len(alphabet))\n",
    "print(X)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print(X.shape)\n",
    "print(y.shape[1])\n",
    "# print(y)\n",
    "# create and fit the model\n",
    "batch_size = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(max_len, )))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=500, batch_size=batch_size, verbose=1)\n",
    "# summarize performance of the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# demonstrate some model predictions\n",
    "for i in range(20):\n",
    "    pattern_index = numpy.random.randint(len(dataX))\n",
    "    pattern = dataX[pattern_index]\n",
    "    x = pad_sequences([pattern], maxlen=max_len, dtype='float32')\n",
    "    # x = numpy.reshape(x, (1, max_len, 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP accuracy is 88.40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM for next item prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM with Variable Length Input Sequences to One Character Output\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# define the raw dataset\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create mapping of characters to integers (0-25) and the reverse\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "num_inputs = 1000\n",
    "max_len = 5\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(num_inputs):\n",
    "    start = numpy.random.randint(len(alphabet)-2)\n",
    "    end = numpy.random.randint(start, min(start+max_len,len(alphabet)-1))\n",
    "    sequence_in = alphabet[start:end+1]\n",
    "    sequence_out = alphabet[end + 1]\n",
    "    dataX.append([char_to_int[char] for char in sequence_in])\n",
    "    dataY.append(char_to_int[sequence_out])\n",
    "    print(sequence_in, '->', sequence_out)\n",
    "# convert list of lists to array and pad sequences if needed\n",
    "X = pad_sequences(dataX, maxlen=max_len, dtype='float32')\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(X, (X.shape[0], max_len, 1))\n",
    "# normalize\n",
    "X = X / float(len(alphabet))\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print(X.shape)\n",
    "print(y.shape[1])\n",
    "# print(y)\n",
    "# create and fit the model\n",
    "batch_size = 10\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], 1)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=500, batch_size=batch_size, verbose=1)\n",
    "# summarize performance of the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# demonstrate some model predictions\n",
    "for i in range(20):\n",
    "    pattern_index = numpy.random.randint(len(dataX))\n",
    "    pattern = dataX[pattern_index]\n",
    "    x = pad_sequences([pattern], maxlen=max_len, dtype='float32')\n",
    "    x = numpy.reshape(x, (1, max_len, 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM accuracy is 95.10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Temporal Recommendation\n",
    "\n",
    "- A novel deep neural network based architecture that models the combination of long-term static and short-term temporal user preferences to improve the recommendation performance\n",
    "\n",
    "- https://github.com/sonyisme/keras-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Content-based Recommendation based on images\n",
    "\n",
    "- https://nycdatascience.com/blog/student-works/deep-learning-meets-recommendation-systems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
